{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Conversions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TjNIAHRfoh6O"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "I91ZSv1So1A1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install dependencies for:**\n",
        "\n",
        "Images of:\n",
        "\n",
        "1.   Printed text\n",
        "\n",
        "\n",
        "*   sudo apt install tesseract-ocr -y\n",
        "*   sudo apt install tesseract-ocr-all -y #all languages\n",
        "\n",
        "2.   Handwriting text\n",
        "\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "PDFs with images of :\n",
        "\n",
        "1.   Printed text\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "2.   Handwriting text\n",
        "\n",
        "*   List item\n",
        "*   List item\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Word document files to txt\n",
        "  1.\n",
        "\n",
        "\n",
        "\n",
        "Audio files to wav and back:\n",
        "\n",
        "*   sudo apt-get install ffmpeg\n",
        "*   sudo apt-get install -y python-pydub\n",
        "\n"
      ],
      "metadata": {
        "id": "jBB9Zfxpo1bG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import preprocessor as p #pip install tweet-preprocessor\n",
        "#from gensim.parsing.preprocessing import remove_stopwords,strip_numeric,strip_punctuation,strip_multiple_whitespaces\n",
        "def clean_tweet_minimal(text):\n",
        "\n",
        "    #text = re.sub(r\"\\r\\n\", \" \", text)\n",
        "    #text = text.replace('\\n', ' ')\n",
        "    text = re.sub(r'[^\\x00-\\x7F]+',' ', text)\n",
        "    text = p.clean(text).lower()\n",
        "    text = re.sub(r'(?:\\$[a-zA-Z]+)', ' ', text)\n",
        "    text = re.sub(r'(?:\\&[a-zA-Z]+;)', ' ', text)\n",
        "    text = re.sub(r'(?:\\#[a-zA-Z]+;)', ' ', text)\n",
        "    text = text.replace('|', ' ')\n",
        "    text = text.replace('\\n', ' ')\n",
        "   \n",
        "\n",
        "    return text\n",
        "directory = '.'# path to directory with csv files containing tweets\n",
        "tweet_frames = []\n",
        "\n",
        "\n",
        "for filename in os.listdir(directory):\n",
        "    if filename.endswith(\".csv\"):\n",
        "        print(filename)\n",
        "        f = open(filename+\".txt\", \"w\")\n",
        "        tweet_file = pd.read_csv(filename)\n",
        "        tweet_file['tweet_clean'] = tweet_file['tweet'].apply(clean_tweet_minimal)\n",
        "        #print(tweet_file['tweet_clean'])\n",
        "        for index, row in tweet_file.iterrows():\n",
        "            tweet = row[\"tweet_clean\"]\n",
        "            print(tweet)\n",
        "            f.write(tweet+\"\\n\")\n",
        "        f.close()\n"
      ],
      "metadata": {
        "id": "6zQMC4ERokc5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "CSV TWEETS TO TEXT\n"
      ],
      "metadata": {
        "id": "fl52XLe3olV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image\n",
        "import pytesseract\n",
        "\n",
        "# If you don't have tesseract executable in your PATH, include the following:\n",
        "pytesseract.pytesseract.tesseract_cmd = r'<full_path_to_your_tesseract_executable>'\n",
        "# Example tesseract_cmd = r'C:\\Program Files (x86)\\Tesseract-OCR\\tesseract'\n",
        "\n",
        "# Simple image to string\n",
        "print(pytesseract.image_to_string(Image.open('sample1.png')))\n",
        "\n",
        "# List of available languages\n",
        "print(pytesseract.get_languages(config=''))\n",
        "\n",
        "# French text image to string\n",
        "print(pytesseract.image_to_string(Image.open('sample1-european.jpg'), lang='fra'))\n",
        "\n",
        "# In order to bypass the image conversions of pytesseract, just use relative or absolute image path\n",
        "# NOTE: In this case you should provide tesseract supported images or tesseract will return error\n",
        "print(pytesseract.image_to_string('sample1.png'))\n",
        "\n",
        "# Batch processing with a single file containing the list of multiple image file paths\n",
        "print(pytesseract.image_to_string('images.txt'))\n",
        "\n",
        "# Timeout/terminate the tesseract job after a period of time\n",
        "try:\n",
        "    print(pytesseract.image_to_string('sample1.jpg', timeout=2)) # Timeout after 2 seconds\n",
        "    print(pytesseract.image_to_string('sample1.jpg', timeout=0.5)) # Timeout after half a second\n",
        "except RuntimeError as timeout_error:\n",
        "    # Tesseract processing is terminated\n",
        "    pass\n",
        "\n",
        "# Get bounding box estimates\n",
        "print(pytesseract.image_to_boxes(Image.open('sample1.png')))\n",
        "\n",
        "# Get verbose data including boxes, confidences, line and page numbers\n",
        "print(pytesseract.image_to_data(Image.open('sample1.png')))\n",
        "\n",
        "# Get information about orientation and script detection\n",
        "print(pytesseract.image_to_osd(Image.open('sample1.png')))\n",
        "\n",
        "# Get a searchable PDF\n",
        "pdf = pytesseract.image_to_pdf_or_hocr('sample1.png', extension='pdf')\n",
        "with open('sample1.pdf', 'w+b') as f:\n",
        "    f.write(pdf) # pdf type is bytes by default\n",
        "\n",
        "# Get HOCR output\n",
        "hocr = pytesseract.image_to_pdf_or_hocr('sample1.png', extension='hocr')\n",
        "\n",
        "# Get ALTO XML output\n",
        "xml = pytesseract.image_to_alto_xml('sample1.png')\n"
      ],
      "metadata": {
        "id": "5w0DaPKDpU61"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OCR GENERAL"
      ],
      "metadata": {
        "id": "YGBge9jVpWOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pytesseract import image_to_string \n",
        "#import Image\n",
        "import cv2, os\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "def image_converter():\n",
        "    #image_directory = input (\"Kindly enter name of directory of photo to be converted from image to text : \")\n",
        "    #try:\n",
        "        #os.chdir(image_directory)\n",
        "    #except:\n",
        "        #image_directory = input (\"Kindly enter correct name of directory of photo to be converted from image to text : \")\n",
        "       # return (\"Kindly enter correct name : \")\n",
        "       \n",
        "    name_of_picture = input (\"Kindly enter name of photo to be converted from image to text :  \")\n",
        "    text_from_file = image_to_string(cv2.imread(name_of_picture))\n",
        "    directory=os.getcwd()\n",
        "    new_name_of_text = input (\"Kindly enter name of text file :  \")\n",
        "    new_name_of_file=os.path.join(directory, new_name_of_text)\n",
        "    \n",
        "    with open(new_name_of_file, \"w\") as file:\n",
        "        file.write(text_from_file)\n",
        "    return (new_name_of_file + \" has now been created from \" + name_of_picture)\n",
        "\n",
        "\n",
        "\n",
        "image_converter()\n"
      ],
      "metadata": {
        "id": "iHcaS02cpYCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "OCR VERSION FOR TEXT PRINT"
      ],
      "metadata": {
        "id": "HDv5pmyip3ns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pdf2image import convert_from_path\n",
        "import os\n",
        " \n",
        " \n",
        "# Store Pdf with convert_from_path function\n",
        "listofnewfiles=[]\n",
        "def pdftoimage(filename):\n",
        " images = convert_from_path(filename)\n",
        " fname, extension=os.path.splittext(filename)\n",
        " \n",
        " for i in range(len(images)):\n",
        "   \n",
        "      # Save pages as images in the pdf\n",
        "    images[i].save(fname+'_'+'page'+ str(i) +'.jpg', 'JPEG')\n",
        "    listofnewfiles.append(fname+'_'+'page'+ str(i) +'.jpg')\n",
        " return (listofnewfiles)\n"
      ],
      "metadata": {
        "id": "Bh49D8mUqH7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF IMAGES: IMAGE PER PAGE"
      ],
      "metadata": {
        "id": "bLThfI68qIeq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 1 \n",
        "# import libraries \n",
        "\n",
        "import fitz \n",
        "\n",
        "import io \n",
        "\n",
        "from PIL import Image \n",
        "\n",
        "  \n",
        "# STEP 2 \n",
        "# file path you want to extract images from \n",
        "\n",
        "file = \"test.pdf\"\n",
        "\n",
        "  \n",
        "# open the file \n",
        "\n",
        "pdf_file = fitz.open(file) \n",
        "\n",
        "  \n",
        "# STEP 3 \n",
        "# iterate over PDF pages \n",
        "\n",
        "for page_index in range(len(pdf_file)): \n",
        "\n",
        "    \n",
        "\n",
        "    # get the page itself \n",
        "\n",
        "    page = pdf_file[page_index] \n",
        "\n",
        "    image_list = page.getImageList() \n",
        "\n",
        "      \n",
        "\n",
        "    # printing number of images found in this page \n",
        "\n",
        "    if image_list: \n",
        "\n",
        "        print(f\"[+] Found a total of {len(image_list)} images in page {page_index}\") \n",
        "\n",
        "    else: \n",
        "\n",
        "        print(\"[!] No images found on page\", page_index) \n",
        "\n",
        "    for image_index, img in enumerate(page.getImageList(), start=1): \n",
        "\n",
        "        \n",
        "\n",
        "        # get the XREF of the image \n",
        "\n",
        "        xref = img[0] \n",
        "\n",
        "          \n",
        "\n",
        "        # extract the image bytes \n",
        "\n",
        "        base_image = pdf_file.extractImage(xref) \n",
        "\n",
        "        image_bytes = base_image[\"image\"] \n",
        "\n",
        "          \n",
        "\n",
        "        # get the image extension \n",
        "        image_ext = base_image[\"ext\"] \n"
      ],
      "metadata": {
        "id": "7xSi856oqMVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PDF IMAGE ALTERNATE"
      ],
      "metadata": {
        "id": "SJfqVmPVq_fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from pocketsphinx import AudioFile, LiveSpeech\n",
        "\n",
        "\n",
        "#acoustic model folder\n",
        "hmm =os.path.join( \"docs/downloads/speechtotext/pocketsphinx\",\"acoustic\" )\n",
        "#language model file\n",
        "lm =os.path.join(\"docs/downloads/speechtotext/pocketsphinx\",\"language.lm.DMP\")\n",
        "#phonetic dictionary\n",
        "dicte =os.path.join(\"docs/downloads/speechtotext/pocketsphinx\",\"dictionary.dic\")\n",
        "#audio file\n",
        "inputfilename =\"edutab_0.wav\"\n",
        "audiodirs=\"docs/downloads/speechtotext/pocketsphinx/audio\"\n",
        "audiodir=\"audio\"\n",
        "#inputfilename=input(\" Enter wav name :  \")\n",
        "\n",
        "\n",
        "def speechtotext(inputfilename):\n",
        "#recorded speech to text\n",
        "  try:\n",
        "    filename,exts=os.path.splitext(inputfilename)\n",
        "#    inputfile=os.path.join(audiodir, inputfilename)\n",
        "    audio = AudioFile(verbose=False,\n",
        "        audio_file=inputfilename,\n",
        "        buffer_size=2048,\n",
        "        no_search=False,\n",
        "        full_utt=False,\n",
        "        hmm=hmm,\n",
        "        lm=lm,\n",
        "        dict=dicte)\n",
        "\n",
        "    listofaudiowords=[]\n",
        "    with open ( filename+\".txt\", \"w+\") as f:\n",
        "    #with open (os.path.join(autodirs, filename+\".txt\"), \"w+\") as f:\n",
        "      for phrase in audio:\n",
        "        listofaudiowords.append(audio)\n",
        "        print (phrase,file=f)\n",
        "\n",
        "    #with open (os.path.join(audiodirs, filename+\".txt\"), \"r\") as f:\n",
        "         #listofaudiowords=f.read()\n",
        "    return listofaudiowords\n",
        "  except Exception as err:\n",
        "    return err\n",
        "\n",
        "\n",
        "\n",
        "#os.system(\"echo\"+str(speechtotext(inputfilename)))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#live speech to text\n",
        "#live_recognizer = LiveSpeech(\n",
        "    #verbose=False,\n",
        "    #sampling_rate=16000,\n",
        "    #buffer_size=2048,\n",
        "    #no_search=False,\n",
        "    #full_utt=False,\n",
        "    #hmm=hmm,\n",
        "    #lm=lm,\n",
        "    #dic=dict)\n",
        "\n",
        "#for phrase in live_recognizer:\n",
        "  #print(phrase)\n"
      ],
      "metadata": {
        "id": "4liBdIgrrCk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Speech to Text"
      ],
      "metadata": {
        "id": "GTCFH8PZrcdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import PyPDF2\n",
        "# pdf_file = open('sample.pdf')\n",
        "# read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
        "# number_of_pages = read_pdf.getNumPages()\n",
        "# page = read_pdf.getPage(0)\n",
        "# page_content = page.extractText()\n",
        "# print page_content\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# from tika import parser # pip install tika\n",
        "# raw = parser.from_file('sample.pdf')\n",
        "# print(raw['content'])\n",
        "\n",
        "\n",
        "import textract\n",
        "text = textract.process(\"ufahamu.docx\")\n",
        "print (text)\n",
        "\n",
        "# import PyPDF2\n",
        "# pdf_file = open('sample.pdf', 'rb')\n",
        "# read_pdf = PyPDF2.PdfFileReader(pdf_file)\n",
        "# number_of_pages = read_pdf.getNumPages()\n",
        "# page = read_pdf.getPage(0)\n",
        "# page_content = page.extractText()\n",
        "# print page_content.encode('utf-8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# import os, subprocess\n",
        "# SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))\n",
        "# args = [\"/usr/local/bin/pdftotext\",\n",
        "#         '-enc',\n",
        "#         'UTF-8',\n",
        "#         \"{}/my-pdf.pdf\".format(SCRIPT_DIR),\n",
        "#         '-']\n",
        "# res = subprocess.run(args, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "# output = res.stdout.decode('utf-8')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# from tika import parser\n",
        "\n",
        "# raw = parser.from_file(\"///Users/Documents/Textos/Texto1.pdf\")\n",
        "# raw = str(raw)\n",
        "\n",
        "# safe_text = raw.encode('utf-8', errors='ignore')\n",
        "\n",
        "# safe_text = str(safe_text).replace(\"\\n\", \"\").replace(\"\\\\\", \"\")\n",
        "# print('--- safe text ---' )\n",
        "# print( safe_text )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# In 2020 the solutions above were not working for the particular pdf I was working with. Below is what did the trick. I am on Windows 10 and Python 3.8\n",
        "\n",
        "# Test pdf file: https://drive.google.com/file/d/1aUfQAlvq5hA9kz2c9CyJADiY3KpY3-Vn/view?usp=sharing\n",
        "\n",
        "# #pip install pdfminer.six\n",
        "# import io\n",
        "\n",
        "# from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
        "# from pdfminer.converter import TextConverter\n",
        "# from pdfminer.layout import LAParams\n",
        "# from pdfminer.pdfpage import PDFPage\n",
        "\n",
        "\n",
        "# def convert_pdf_to_txt(path):\n",
        "#     '''Convert pdf content from a file path to text\n",
        "\n",
        "#     :path the file path\n",
        "#     '''\n",
        "#     rsrcmgr = PDFResourceManager()\n",
        "#     codec = 'utf-8'\n",
        "#     laparams = LAParams()\n",
        "\n",
        "#     with io.StringIO() as retstr:\n",
        "#         with TextConverter(rsrcmgr, retstr, codec=codec,\n",
        "#                            laparams=laparams) as device:\n",
        "#             with open(path, 'rb') as fp:\n",
        "#                 interpreter = PDFPageInterpreter(rsrcmgr, device)\n",
        "#                 password = \"\"\n",
        "#                 maxpages = 0\n",
        "#                 caching = True\n",
        "#                 pagenos = set()\n",
        "\n",
        "#                 for page in PDFPage.get_pages(fp,\n",
        "#                                               pagenos,\n",
        "#                                               maxpages=maxpages,\n",
        "#                                               password=password,\n",
        "#                                               caching=caching,\n",
        "#                                               check_extractable=True):\n",
        "#                     interpreter.process_page(page)\n",
        "\n",
        "#                 return retstr.getvalue()\n",
        "\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     print(convert_pdf_to_txt('C:\\\\Path\\\\To\\\\Test_PDF.pdf')) \n",
        "\n"
      ],
      "metadata": {
        "id": "3_DZXf1crga0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RTF, DOCX, DOC TO WORD"
      ],
      "metadata": {
        "id": "8TB9uY2isYSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#splitter\n",
        "\n",
        "import pydub,os\n",
        "import numpy as np\n",
        "                                                  \n",
        "sound_file = pydub.AudioSegment.from_mp3(\"audio/3t - I Need You.mp3\")\n",
        "sound_file_Value = np.array(sound_file.get_array_of_samples())\n",
        "# milliseconds in the sound track\n",
        "ranges = [(30000,40000),(50000,60000),(80000,90000),(100000,110000),(150000,180000)] \n",
        "\n",
        "for x, y in ranges:\n",
        "    new_file=sound_file_Value[x : y]\n",
        "    song = pydub.AudioSegment(new_file.tobytes(), frame_rate=sound_file.frame_rate,sample_width=sound_file.sample_width,channels=1)\n",
        "    song.export(os.path.join(\"newaudio\",str(x) + \"-\" + str(y) +\".mp3\"), format=\"mp3\")\n",
        "                                                                                                                                \n",
        "\n",
        "#stereo to mono\n",
        "\n",
        "# splitting stereo audio to mono\n",
        "# using pydub\n",
        "  \n",
        "# Import AudioSegment from pydub\n",
        "from pydub import AudioSegment\n",
        "  \n",
        "# Open the stereo audio file as\n",
        "# an AudioSegment instance\n",
        "stereo_audio = AudioSegment.from_file(\n",
        "    \"audio/3t - I Need You.mp3\", format=\"mp3\")\n",
        "                                            \n",
        "# Calling the split_to_mono method\n",
        "# on the stereo audio file\n",
        "mono_audios = stereo_audio.split_to_mono()\n",
        "  \n",
        "# Exporting/Saving the two mono\n",
        "# audio files present at index 0(left)\n",
        "# and index 1(right) of list returned\n",
        "# by split_to_mono method\n",
        "mono_left = mono_audios[0].export(\n",
        "    \"newaudio/3t-I-Need-You-left.mp3\" , format=\"mp3\")\n",
        "                                  \n",
        "mono_right = mono_audios[1].export(\n",
        "    \"newaudio/3t-I-Need-You-right.mp3\",    format=\"mp3\")\n",
        "\n",
        "\n",
        "\n",
        "#convert file\n",
        "import pydub\n",
        "sound = pydub.AudioSegment.from_mp3(\"audio/3t - I Need You.mp3\")\n",
        "sound.export(\"3T-Ineedyoupydub.wav\", format=\"wav\")\n",
        "                             \n",
        "\n",
        "import subprocess\n",
        "\n",
        "                                                   \n",
        "subprocess.call(['sox', 'audio/3t - I Need You.mp3', '-e', 'mu-law', \n",
        "                   '-r', '16k', 'audio/3t-Ineedyousox.wav', 'remix', '1,2'])\n"
      ],
      "metadata": {
        "id": "rqQUxPeds9GX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "TO WAV, MONO, BIT RATE, BIT DEPTH,SPLIT LENGTH"
      ],
      "metadata": {
        "id": "Q43HzIGhs-hm"
      }
    }
  ]
}